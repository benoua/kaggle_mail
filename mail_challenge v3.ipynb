{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful fns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_callback(df, mail_id, sender, receiver, mid_best_cosine, likelihood, p1, p2, p3 ):\n",
    "    \n",
    "    df.loc[-1] = [ mail_id, sender, receiver, mid_best_cosine, likelihood, p1, p2, p3]\n",
    "    df.index = df.index + 1\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk([list(np.arange(10))], [list( np.random.permutation(10))], k=10)\n",
    "mapk([['a', 'b']], [['b', 'c', 'd']], k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = \"Data/\"\n",
    "\n",
    "##########################\n",
    "# load some of the files #                           \n",
    "##########################\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "\n",
    "training_info = pd.read_csv('training_info_processed.csv', sep=',', header=0)\n",
    "\n",
    "test_info = pd.read_csv('test_info_processed.csv', sep=',', header=0)\n",
    "\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes :\n",
    "Careful, there is duplicates in 'mid' for training_info and test_info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# create some handy structures #                    \n",
    "################################\n",
    "                            \n",
    "# convert training set to dictionary\n",
    "emails_ids_per_sender = {}\n",
    "for index, series in training.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    ids = row[1:][0].split(' ')\n",
    "    emails_ids_per_sender[sender] = ids\n",
    "\n",
    "# save all unique sender names\n",
    "all_senders = emails_ids_per_sender.keys()\n",
    "\n",
    "# create address book with frequency information for each user\n",
    "address_books = {}\n",
    "i = 0\n",
    "\n",
    "if (os.path.isfile('all_users.pkl')) & (os.path.isfile('address_books.pkl')) & (os.path.isfile('all_recs.pkl')):\n",
    "    all_recs = pickle.load(open('all_recs.pkl', 'rb'))                                   \n",
    "    all_users = pickle.load(open('all_users.pkl', 'rb'))\n",
    "    address_books = pickle.load(open('address_books.pkl', 'rb'))\n",
    "else:\n",
    "    for sender, ids in emails_ids_per_sender.items():\n",
    "        recs_temp = []\n",
    "        for my_id in ids:\n",
    "\n",
    "            '''Recipients'''\n",
    "            recipients = training_info[training_info['mid']==int(my_id)]['recipients'].tolist()\n",
    "            recipients = recipients[0].split(' ')\n",
    "            # keep only legitimate email addresses\n",
    "            recipients = [rec for rec in recipients if '@' in rec]\n",
    "            recs_temp.append(recipients)\n",
    "\n",
    "\n",
    "            '''mail info'''\n",
    "\n",
    "        # flatten    \n",
    "        recs_temp = [elt for sublist in recs_temp for elt in sublist]\n",
    "        # compute recipient counts\n",
    "        rec_occ = dict(Counter(recs_temp))\n",
    "        # order by frequency\n",
    "        sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse = True)\n",
    "        # save\n",
    "        address_books[sender] = sorted_rec_occ\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print (i)\n",
    "        i += 1\n",
    "\n",
    "    # save all unique recipient names    \n",
    "    all_recs = list(set([elt[0] for sublist in address_books.values() for elt in sublist]))\n",
    "\n",
    "    # save all unique user names \n",
    "    all_users = []\n",
    "    all_users.extend(all_senders)\n",
    "    all_users.extend(all_recs)\n",
    "    all_users = list(set(all_users))\n",
    "    \n",
    "    pickle.dump(all_recs, open('all_recs.pkl', 'wb')) \n",
    "    pickle.dump(all_users, open('all_users.pkl', 'wb')) \n",
    "    pickle.dump(address_books, open('address_books.pkl', 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DG and MG\n"
     ]
    }
   ],
   "source": [
    "'''Construct the communication graph of senders/receivers'''\n",
    "\n",
    "import networkx as nx\n",
    "import pdb\n",
    "\n",
    "DG_path = 'DG.text'\n",
    "MG_path = 'MG.text'\n",
    "\n",
    "# check if it already exists\n",
    "if (os.path.isfile(DG_path)) & (os.path.isfile(MG_path)):\n",
    "    DG = pickle.load(open(DG_path))\n",
    "    MG = pickle.load(open(MG_path))\n",
    "\n",
    "else:\n",
    "    DG=nx.DiGraph()\n",
    "    MG = nx.MultiDiGraph()\n",
    "\n",
    "    for sender, ids in emails_ids_per_sender.items():\n",
    "    #     recs_temp = []\n",
    "        DG.add_node(sender)\n",
    "        MG.add_node(sender)\n",
    "        recs_temp = []\n",
    "        recipients = []\n",
    "        for my_id in ids:\n",
    "            recipients = training_info[training_info['mid']==int(my_id)]['recipients'].tolist()\n",
    "            recipients = recipients[0].split(' ')\n",
    "            # keep only legitimate email addresses\n",
    "            recipients = [rec for rec in recipients if \"@\" in rec]\n",
    "\n",
    "            DG.add_nodes_from(recipients)\n",
    "            MG.add_nodes_from(recipients)\n",
    "\n",
    "            for recipient in recipients:\n",
    "                MG.add_edge(sender, recipient, email = my_id)\n",
    "                if DG.has_edge(sender, recipient):\n",
    "                    # we added this one before, just increase the weight by one\n",
    "                    DG[sender][recipient]['weight'] += 1\n",
    "                else:\n",
    "                    # new edge. add with weight=1\n",
    "                    DG.add_edge(sender, recipient, weight = 1)\n",
    "    '''saving graphs'''\n",
    "    print(\"Saving DG and MG\")\n",
    "    pickle.dump(DG, open('DG.txt', 'wb'))\n",
    "    pickle.dump(MG, open('MG.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # from nltk import FreqDist\n",
    "big_string = training_info['pre_processed'].str.cat(sep=',')\n",
    "fdistr = Counter(big_string.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_all_body_column(training_info, test=False):\n",
    "    process = lambda x: pre_process_to_string(x)\n",
    "    training_info['pre_processed'] = training_info['body'].apply(process)\n",
    "    if test :\n",
    "        training_info.to_csv(\"test_info_processed.csv\")\n",
    "    else :\n",
    "        training_info.to_csv(\"training_info_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/benlet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /home/benlet/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/benlet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/benlet/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Mail steming'''\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('maxent_treebank_pos_tagger') # for POS tagging\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pre_process(content):\n",
    "    # Remove formatting\n",
    "    content =  re.sub(\"\\s+\", \" \", content)\n",
    "    # Convert to lower case\n",
    "    content = content.lower()\n",
    "    \n",
    "    # Replace punctuation by space (preserving intra-word dashes)\n",
    "    content = \"\".join(letter if letter not in punct else \" \" for letter in content )\n",
    "    \n",
    "    # Remove punctuation (preserving intra-word dashes)\n",
    "    content = \"\".join(letter for letter in content if letter not in punct)\n",
    "    \n",
    "    # Remove extra white space\n",
    "    content = re.sub(\" +\",\" \", content)\n",
    "    # Remove leading and trailing white space\n",
    "    content = content.strip()\n",
    "    # Tokenize and stopword removal\n",
    "    tokens_keep  = [word for word in content.split() if word not in stpwds] \n",
    "    # POS-tag \n",
    "    tagged_tokens = nltk.pos_tag(tokens_keep)\n",
    "#     Keep only nouns and adjectives    \n",
    "    tokens_keep = [pair[0] for pair in tagged_tokens if (pair[1] in [\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"JJ\",\"JJS\",\"JJR\"])]\n",
    "    # Apply Porter stemmer\n",
    "    tokens_keep = [stemmer.stem(token) for token in tokens_keep]\n",
    "    return tokens_keep\n",
    "\n",
    "def pre_process_to_string(content):\n",
    "    return \",\".join(pre_process(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process_all_body_column(training_info)\n",
    "# process_all_body_column(test_info, test = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_info.fillna(\"\", inplace = True)\n",
    "test_info.fillna(\"\", inplace = True)\n",
    "nb_training = training_info.shape[0]\n",
    "nb_test = test_info.shape[0]\n",
    "all_mails = pd.concat([training_info['pre_processed'], test_info['pre_processed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45975, 118013)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TF-IDF on emails'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_all_mails = vectorizer.fit_transform(all_mails)\n",
    "X_all_mails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.random.permutation(nb_training)\n",
    "train_id = mask[:int(0.98*nb_training)]\n",
    "cv_id = mask[int(0.98*nb_training):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mails_train = X_all_mails[train_id, :]\n",
    "X_mails_cv = X_all_mails[cv_id, :]\n",
    "X_mails_test = X_all_mails[nb_training:, :]\n",
    "df_train = training_info.iloc[train_id].reset_index()\n",
    "df_cv = training_info.iloc[cv_id].reset_index()\n",
    "df_test = test_info.reset_index()\n",
    "len(df_cv) == X_mails_cv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def cosine_df(df1, df2, idx1, idx2):\n",
    "    return cosine_similarity(np.atleast_2d(df1.loc[idx1].values), np.atleast_2d(df2.loc[idx2].values))[0][0]\n",
    "\n",
    "def cosine_sparse(X1, X2, idx1, idx2):\n",
    "    if is_csr_matrix_only_zeroes(X1[idx1]) or is_csr_matrix_only_zeroes(X2[idx2]):\n",
    "        out = 0\n",
    "    else : \n",
    "        out = cosine_similarity(X1[idx1], X2[idx2])[0][0]\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing likelihoods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Sender Likelihood'''\n",
    "k = 10\n",
    "# frequency based probability\n",
    "sender = 'sylvia.hu@enron.com'\n",
    "receiver = 'britt.davis@enron.com'\n",
    "\n",
    "def total_incoming_mails(receiver_):\n",
    "    return sum([DG[sender_][receiver_]['weight'] \\\n",
    "                for sender_ in DG.predecessors(receiver_)])\n",
    "\n",
    "# dictionnary of incoming mails per receiver \n",
    "dict_incoming_mails = {}\n",
    "for recipient in all_recs:\n",
    "    dict_incoming_mails[recipient] = total_incoming_mails(recipient)\n",
    "    \n",
    "\n",
    "def p_fred_S_sachant_R(DG, sender, receiver, k=k):\n",
    "    \n",
    "    out = DG[sender][receiver]['weight']/ \\\n",
    "                dict_incoming_mails[receiver]\n",
    "    \n",
    "#     save_callback(\"p(S/R)\", None, sender, receiver, None, out )\n",
    "    return out\n",
    "    \n",
    "# co-occurence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_fred_S_sachant_R(DG=DG, sender=sender, receiver=receiver, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Recipient Likelihood'''\n",
    "\n",
    "# number of emails received by Receiver / Total # of emails sent\n",
    "\n",
    "def total_mail_sent(DG=DG):\n",
    "    A = np.array(list(DG.edges_iter(data='weight', default=1)))\n",
    "    return np.sum(A[:,2:].flatten().astype(np.int),axis=0)\n",
    "\n",
    "Total_emails_sent = total_mail_sent()\n",
    "\n",
    "def p_R(DG, receiver):\n",
    "    out = dict_incoming_mails[receiver] /Total_emails_sent\n",
    "#     save_callback(\"p(R)\", None, None, receiver, None, out )\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 21.7 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.2967627231646784e-05"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "p_R(DG=DG, receiver= receiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Email likelihood with TF_IDF'''\n",
    "\n",
    "\n",
    "def p_e_sachant_r_s_tfidf(email_id, sender, receiver, cv_or_test= 'cv'):\n",
    "    '''for a given email, the sender of this emails and potential recipients, returns \n",
    "    - the maximum cosine_similarity between the given email and all the emails between sender & receiver'''\n",
    "    out = 1e-15\n",
    "    best_cosine = None\n",
    "    if MG.get_edge_data(sender,receiver): \n",
    "        '''list all mails between sender and receiver'''\n",
    "        mail_list = [ a for sublist in \\\n",
    "                     [list(s.values()) for s in MG.get_edge_data(sender,receiver).values()] for a in sublist  ]\n",
    "        \n",
    "        mail_list = [mid for mid in mail_list if df_cv[df_cv['mid'] == int(mid)].empty == True  ]\n",
    "        \n",
    "        if mail_list:\n",
    "            mail_tf_idf_scores = []\n",
    " \n",
    "            for mid in mail_list:\n",
    "                idx_train = df_train[df_train['mid'] == int(mid)].index.values[0]\n",
    "                if cv_or_test == 'test':\n",
    "                    idx_test = df_test[df_test['mid'] == int(email_id)].index.values[0]\n",
    "                    mail_tf_idf_scores.append( cosine_sparse(X_mails_train, X_mails_test, idx_train, idx_test ) )\n",
    "                else :\n",
    "                    idx_cv = df_cv[df_cv['mid'] == int(email_id)].index.values[0]\n",
    "                    mail_tf_idf_scores.append( cosine_sparse(X_mails_train, X_mails_cv, idx_train, idx_cv ) )\n",
    "\n",
    "            if mail_tf_idf_scores:\n",
    "                out = np.max(np.array(mail_tf_idf_scores))\n",
    "                best_cosine = mail_list[np.argmax(np.array(mail_tf_idf_scores))]\n",
    "                if out ==0 :\n",
    "                    out = 1e-16\n",
    "#                 save_callback(\"p(E/S,R)\", email_id, sender, receiver, None, out)\n",
    "    return out , best_cosine\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# p_e_sachant_r_s_tfidf(email_id, sender, receiver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the probabilistic model on CV Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "CV Mail 0 over 873 calculated in 0 min\n",
      "CV Mail 1 over 873 calculated in 0 min\n",
      "CV Mail 2 over 873 calculated in 0 min\n",
      "CV Mail 3 over 873 calculated in 0 min\n",
      "CV Mail 4 over 873 calculated in 0 min\n",
      "CV Mail 5 over 873 calculated in 1 min\n",
      "CV Mail 6 over 873 calculated in 1 min\n",
      "CV Mail 7 over 873 calculated in 1 min\n",
      "CV Mail 8 over 873 calculated in 1 min\n",
      "CV Mail 9 over 873 calculated in 1 min\n",
      "CV Mail 10 over 873 calculated in 1 min\n",
      "CV Mail 11 over 873 calculated in 1 min\n",
      "CV Mail 12 over 873 calculated in 2 min\n",
      "CV Mail 13 over 873 calculated in 2 min\n",
      "CV Mail 14 over 873 calculated in 2 min\n",
      "CV Mail 15 over 873 calculated in 2 min\n",
      "CV Mail 16 over 873 calculated in 2 min\n",
      "CV Mail 17 over 873 calculated in 2 min\n",
      "CV Mail 18 over 873 calculated in 3 min\n",
      "CV Mail 19 over 873 calculated in 3 min\n",
      "CV Mail 20 over 873 calculated in 3 min\n",
      "CV Mail 21 over 873 calculated in 3 min\n",
      "CV Mail 22 over 873 calculated in 3 min\n",
      "CV Mail 23 over 873 calculated in 3 min\n",
      "CV Mail 24 over 873 calculated in 3 min\n",
      "CV Mail 25 over 873 calculated in 3 min\n",
      "CV Mail 26 over 873 calculated in 4 min\n",
      "CV Mail 27 over 873 calculated in 4 min\n",
      "CV Mail 28 over 873 calculated in 4 min\n",
      "CV Mail 29 over 873 calculated in 5 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "df_proba_cv =pd.DataFrame(columns=[\"mail_id\",\"sender\", \"receiver\",\"mid_best_cosine\", \"likelihood\",'P(E/R,S)', 'P(S/E)', 'P(R)'])\n",
    "start_time = time.time()\n",
    "print(\"Starting\")\n",
    "for index, row in df_cv[:30].iterrows():\n",
    "    mail_id = df_cv.loc[index]['mid']\n",
    "    sender = training[training['mids'].str.contains(str(mail_id))]['sender'].values[0]\n",
    "    \n",
    "    receiver_count = 0\n",
    "    for (receiver, _) in address_books[sender][:300]:\n",
    "        \n",
    "\n",
    "        a2 = p_fred_S_sachant_R(DG, sender, receiver)\n",
    "        a3 = p_R(DG, receiver)\n",
    "        a1, mid_best_cosine = p_e_sachant_r_s_tfidf(mail_id,sender,receiver)\n",
    "        out = a1 * a2 * a3 \n",
    "        save_callback( df_proba_cv, mail_id, sender, receiver, mid_best_cosine, out, a1, a2, a3)\n",
    "    receiver_count += 1\n",
    "    print (\"CV Mail %d over %d calculated in %d min\" % (index, len(df_cv), (time.time() - start_time)/60 ))\n",
    "\n",
    "df_proba_cv.to_csv(\"df_proba_cv.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_receivers = 10\n",
    "def f(weights = [0,1,1]):\n",
    "    mapk_predicted =[]\n",
    "    mapk_true = []\n",
    "    mapk_index = []\n",
    "\n",
    "    for index, row in df_cv[:30].iterrows():\n",
    "        mid_cv = row[3]\n",
    "    #     print(mid_cv)\n",
    "        df_pow = df_proba_cv[df_proba_cv['mail_id'] == mid_cv][['P(E/R,S)', 'P(S/E)', 'P(R)']].pow(weights)\n",
    "\n",
    "        df_pow['likelihood'] = df_pow.prod(axis = 1)\n",
    "        df_pow = df_pow.sort_values(by='likelihood', ascending = False)\n",
    "        receiver_names = df_proba_cv.loc[df_pow.index][:top_receivers]['receiver'].values\n",
    "    #     receiver_list_predicted = \" \".join(receiver_names)\n",
    "        receiver_list_predicted = receiver_names\n",
    "\n",
    "        receiver_list_true = training_info[training_info['mid'] ==mid_cv]['recipients'].values[0].split(\" \")\n",
    "#         print(receiver_list_predicted[:top_receivers])\n",
    "#         print(\"######\")\n",
    "#         print(receiver_list_true[:top_receivers])\n",
    "#         print(apk(receiver_list_true,receiver_list_predicted, k=10))\n",
    "        mapk_index.append(mid_cv)\n",
    "        mapk_predicted.append(receiver_list_predicted)\n",
    "        mapk_true.append(receiver_list_true)\n",
    "    \n",
    "    return -mapk(mapk_true, mapk_predicted, k=10) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "weights_ini  = [0.5, 10, 1]\n",
    "best_weights = minimize(f, weights_ini, method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.216199074074\n",
      "[ 0.51666667  9.5         1.03333333]\n"
     ]
    }
   ],
   "source": [
    "print(- f(best_weights['x']))\n",
    "print (best_weights['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41101851851851851"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- f([1, 10, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 0.51666667,  9.5       ,  1.03333333],\n",
       "       [ 0.51666463,  9.50006104,  1.03333537],\n",
       "       [ 0.51666294,  9.50002035,  1.03333605],\n",
       "       [ 0.5166648 ,  9.50001017,  1.03333774]]), array([-0.21619907, -0.21619907, -0.21619907, -0.21619907]))\n",
       "           fun: -0.21619907407407407\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 74\n",
       "           nit: 17\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([ 0.51666667,  9.5       ,  1.03333333])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Test Sender 0 over 2362 calculated in 1 min\n",
      "Test Sender 1 over 2362 calculated in 1 min\n",
      "Test Sender 2 over 2362 calculated in 1 min\n",
      "Test Sender 3 over 2362 calculated in 2 min\n",
      "Test Sender 4 over 2362 calculated in 2 min\n",
      "Test Sender 5 over 2362 calculated in 4 min\n",
      "Test Sender 6 over 2362 calculated in 4 min\n",
      "Test Sender 7 over 2362 calculated in 5 min\n",
      "Test Sender 8 over 2362 calculated in 5 min\n",
      "Test Sender 9 over 2362 calculated in 5 min\n",
      "Test Sender 10 over 2362 calculated in 5 min\n",
      "Test Sender 11 over 2362 calculated in 6 min\n",
      "Test Sender 12 over 2362 calculated in 6 min\n",
      "Test Sender 13 over 2362 calculated in 6 min\n",
      "Test Sender 14 over 2362 calculated in 6 min\n",
      "Test Sender 15 over 2362 calculated in 7 min\n",
      "Test Sender 16 over 2362 calculated in 8 min\n",
      "Test Sender 17 over 2362 calculated in 8 min\n",
      "Test Sender 18 over 2362 calculated in 9 min\n",
      "Test Sender 19 over 2362 calculated in 11 min\n",
      "Test Sender 20 over 2362 calculated in 14 min\n",
      "Test Sender 21 over 2362 calculated in 14 min\n",
      "Test Sender 22 over 2362 calculated in 17 min\n",
      "Test Sender 23 over 2362 calculated in 19 min\n",
      "Test Sender 24 over 2362 calculated in 20 min\n",
      "Test Sender 25 over 2362 calculated in 22 min\n",
      "Test Sender 26 over 2362 calculated in 23 min\n",
      "Test Sender 27 over 2362 calculated in 23 min\n",
      "Test Sender 28 over 2362 calculated in 24 min\n",
      "Test Sender 29 over 2362 calculated in 24 min\n",
      "Test Sender 30 over 2362 calculated in 25 min\n",
      "Test Sender 31 over 2362 calculated in 25 min\n",
      "Test Sender 32 over 2362 calculated in 26 min\n",
      "Test Sender 33 over 2362 calculated in 26 min\n",
      "Test Sender 34 over 2362 calculated in 26 min\n",
      "Test Sender 35 over 2362 calculated in 27 min\n",
      "Test Sender 36 over 2362 calculated in 27 min\n",
      "Test Sender 37 over 2362 calculated in 27 min\n",
      "Test Sender 38 over 2362 calculated in 27 min\n",
      "Test Sender 39 over 2362 calculated in 30 min\n",
      "Test Sender 40 over 2362 calculated in 30 min\n",
      "Test Sender 41 over 2362 calculated in 30 min\n",
      "Test Sender 42 over 2362 calculated in 30 min\n",
      "Test Sender 43 over 2362 calculated in 31 min\n",
      "Test Sender 44 over 2362 calculated in 31 min\n",
      "Test Sender 45 over 2362 calculated in 32 min\n",
      "Test Sender 46 over 2362 calculated in 32 min\n",
      "Test Sender 47 over 2362 calculated in 33 min\n",
      "Test Sender 48 over 2362 calculated in 33 min\n",
      "Test Sender 49 over 2362 calculated in 34 min\n",
      "Test Sender 50 over 2362 calculated in 34 min\n",
      "Test Sender 51 over 2362 calculated in 35 min\n",
      "Test Sender 52 over 2362 calculated in 35 min\n",
      "Test Sender 53 over 2362 calculated in 35 min\n",
      "Test Sender 54 over 2362 calculated in 36 min\n",
      "Test Sender 55 over 2362 calculated in 39 min\n",
      "Test Sender 56 over 2362 calculated in 39 min\n",
      "Test Sender 57 over 2362 calculated in 40 min\n",
      "Test Sender 58 over 2362 calculated in 40 min\n",
      "Test Sender 59 over 2362 calculated in 41 min\n",
      "Test Sender 60 over 2362 calculated in 41 min\n",
      "Test Sender 61 over 2362 calculated in 41 min\n",
      "Test Sender 62 over 2362 calculated in 42 min\n",
      "Test Sender 63 over 2362 calculated in 42 min\n",
      "Test Sender 64 over 2362 calculated in 43 min\n",
      "Test Sender 65 over 2362 calculated in 43 min\n",
      "Test Sender 66 over 2362 calculated in 47 min\n",
      "Test Sender 67 over 2362 calculated in 48 min\n",
      "Test Sender 68 over 2362 calculated in 48 min\n",
      "Test Sender 69 over 2362 calculated in 48 min\n",
      "Test Sender 70 over 2362 calculated in 48 min\n",
      "Test Sender 71 over 2362 calculated in 49 min\n",
      "Test Sender 72 over 2362 calculated in 49 min\n",
      "Test Sender 73 over 2362 calculated in 49 min\n",
      "Test Sender 74 over 2362 calculated in 50 min\n",
      "Test Sender 75 over 2362 calculated in 50 min\n",
      "Test Sender 76 over 2362 calculated in 51 min\n",
      "Test Sender 77 over 2362 calculated in 51 min\n",
      "Test Sender 78 over 2362 calculated in 52 min\n",
      "Test Sender 79 over 2362 calculated in 52 min\n",
      "Test Sender 80 over 2362 calculated in 52 min\n",
      "Test Sender 81 over 2362 calculated in 52 min\n",
      "Test Sender 82 over 2362 calculated in 53 min\n",
      "Test Sender 83 over 2362 calculated in 57 min\n",
      "Test Sender 84 over 2362 calculated in 62 min\n",
      "Test Sender 85 over 2362 calculated in 62 min\n",
      "Test Sender 86 over 2362 calculated in 64 min\n",
      "Test Sender 87 over 2362 calculated in 66 min\n",
      "Test Sender 88 over 2362 calculated in 67 min\n",
      "Test Sender 89 over 2362 calculated in 68 min\n",
      "Test Sender 90 over 2362 calculated in 68 min\n",
      "Test Sender 91 over 2362 calculated in 70 min\n",
      "Test Sender 92 over 2362 calculated in 71 min\n",
      "Test Sender 93 over 2362 calculated in 73 min\n",
      "Test Sender 94 over 2362 calculated in 73 min\n",
      "Test Sender 95 over 2362 calculated in 73 min\n",
      "Test Sender 96 over 2362 calculated in 79 min\n",
      "Test Sender 97 over 2362 calculated in 79 min\n",
      "Test Sender 98 over 2362 calculated in 79 min\n",
      "Test Sender 99 over 2362 calculated in 80 min\n",
      "Test Sender 100 over 2362 calculated in 80 min\n",
      "Test Sender 101 over 2362 calculated in 81 min\n",
      "Test Sender 102 over 2362 calculated in 83 min\n",
      "Test Sender 103 over 2362 calculated in 85 min\n",
      "Test Sender 104 over 2362 calculated in 86 min\n",
      "Test Sender 105 over 2362 calculated in 86 min\n",
      "Test Sender 106 over 2362 calculated in 86 min\n",
      "Test Sender 107 over 2362 calculated in 87 min\n",
      "Test Sender 108 over 2362 calculated in 88 min\n",
      "Test Sender 109 over 2362 calculated in 88 min\n",
      "Test Sender 110 over 2362 calculated in 90 min\n",
      "Test Sender 111 over 2362 calculated in 91 min\n",
      "Test Sender 112 over 2362 calculated in 91 min\n",
      "Test Sender 113 over 2362 calculated in 92 min\n",
      "Test Sender 114 over 2362 calculated in 92 min\n",
      "Test Sender 115 over 2362 calculated in 92 min\n",
      "Test Sender 116 over 2362 calculated in 92 min\n",
      "Test Sender 117 over 2362 calculated in 93 min\n",
      "Test Sender 118 over 2362 calculated in 93 min\n",
      "Test Sender 119 over 2362 calculated in 93 min\n",
      "Test Sender 120 over 2362 calculated in 94 min\n",
      "Test Sender 121 over 2362 calculated in 95 min\n",
      "Test Sender 122 over 2362 calculated in 95 min\n",
      "Test Sender 123 over 2362 calculated in 95 min\n",
      "Test Sender 124 over 2362 calculated in 96 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "df_proba_test =pd.DataFrame(columns=[\"mail_id\",\"sender\", \"receiver\",\"mid_best_cosine\", \"likelihood\",'P(E/R,S)', 'P(S/E)', 'P(R)'])\n",
    "start_time = time.time()\n",
    "print(\"Starting\")\n",
    "for index, row in test.iterrows():\n",
    "    name_ids = row.tolist()\n",
    "    sender = name_ids[0]\n",
    "    # get IDs of the emails for which recipient prediction is needed\n",
    "    mids_predict = name_ids[1].split(' ')\n",
    "    mids_predict = [int(my_id) for my_id in mids_predict]\n",
    "    \n",
    "    receiver_count = 0\n",
    "    for (receiver, _) in address_books[sender][:20]:\n",
    "        for mail_id in mids_predict:\n",
    "            \n",
    "            a2 = p_fred_S_sachant_R(DG, sender, receiver)\n",
    "            a3 = p_R(DG, receiver)\n",
    "            a1, mid_best_cosine = p_e_sachant_r_s_tfidf(mail_id,sender,receiver, 'test')\n",
    "            out = a1 * a2 * a3 \n",
    "            save_callback( df_proba_test, mail_id, sender, receiver, mid_best_cosine, out, a1, a2, a3)\n",
    "        receiver_count += 1\n",
    "    print (\"Test Sender %d over %d calculated in %d min\" % (index, len(df_test), (time.time() - start_time)/60 ))\n",
    "\n",
    "df_proba_test.to_csv(\"df_proba_test.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail_id</th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>mid_best_cosine</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>P(E/R,S)</th>\n",
       "      <th>P(S/E)</th>\n",
       "      <th>P(R)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>298389.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>278578</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.335253</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>332383.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>161033</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.124243</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>298390.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>284071.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>366982.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>81773.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.170698</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>81791.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>278520</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.223972</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>53502.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>284078.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.068112</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>285309.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>284037.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>298238</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.151187</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>52060.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>298313</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.282331</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>199873.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>298313</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.426619</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>81820.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>161037</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.181756</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53513.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>53532</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.425885</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>94338.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.348252</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>390529.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>382641</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.047760</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>267637.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.150724</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>162488.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>274873.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.186241</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>298389.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>278578</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.335253</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>332383.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>161033</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.124243</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>298390.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>284071.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>366982.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>81773.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.170698</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>81791.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>278520</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.223972</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53502.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>284078.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.068112</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>285309.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>284037.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298238</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.151187</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52060.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298313</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.282331</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>199873.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298313</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.426619</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81820.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>392289</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.213249</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53513.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>53532</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.425885</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>94338.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.348252</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>390529.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298162</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.010882</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>267637.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.150724</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>162488.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>274873.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>298326</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.186241</td>\n",
       "      <td>0.299242</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>298389.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>278578</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.335253</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>332383.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>161033</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.124243</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>298390.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>284071.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>94855</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.035051</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>366982.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81773.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.170698</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81791.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>278595</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.222070</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53502.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284078.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>266070</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.068112</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285309.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>160998</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mail_id                   sender                    receiver  \\\n",
       "49  298389.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "48  332383.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "47  298390.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "46  284071.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "45  366982.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "44   81773.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "43   81791.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "42   53502.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "41  284078.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "40  285309.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "39  284037.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "38   52060.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "37  199873.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "36   81820.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "35   53513.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "34   94338.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "33  390529.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "32  267637.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "31  162488.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "30  274873.0  karen.buckley@enron.com        scott.neal@enron.com   \n",
       "29  298389.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "28  332383.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "27  298390.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "26  284071.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "25  366982.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "24   81773.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "23   81791.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "22   53502.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "21  284078.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "20  285309.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "19  284037.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "18   52060.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "17  199873.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "16   81820.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "15   53513.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "14   94338.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "13  390529.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "12  267637.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "11  162488.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "10  274873.0  karen.buckley@enron.com  hunter.s.shively@enron.com   \n",
       "9   298389.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "8   332383.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "7   298390.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "6   284071.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "5   366982.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "4    81773.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "3    81791.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "2    53502.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "1   284078.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "0   285309.0  karen.buckley@enron.com       john.arnold@enron.com   \n",
       "\n",
       "   mid_best_cosine  likelihood  P(E/R,S)    P(S/E)      P(R)  \n",
       "49          278578    0.000103  0.335253  0.291228  0.001056  \n",
       "48          161033    0.000038  0.124243  0.291228  0.001056  \n",
       "47          160998    0.000046  0.148093  0.291228  0.001056  \n",
       "46          298326    0.000008  0.027253  0.291228  0.001056  \n",
       "45          266070    0.000021  0.067654  0.291228  0.001056  \n",
       "44          266070    0.000052  0.170698  0.291228  0.001056  \n",
       "43          278520    0.000069  0.223972  0.291228  0.001056  \n",
       "42          160998    0.000046  0.148093  0.291228  0.001056  \n",
       "41          266070    0.000021  0.068112  0.291228  0.001056  \n",
       "40          160998    0.000046  0.148093  0.291228  0.001056  \n",
       "39          298238    0.000046  0.151187  0.291228  0.001056  \n",
       "38          298313    0.000087  0.282331  0.291228  0.001056  \n",
       "37          298313    0.000131  0.426619  0.291228  0.001056  \n",
       "36          161037    0.000056  0.181756  0.291228  0.001056  \n",
       "35           53532    0.000131  0.425885  0.291228  0.001056  \n",
       "34          298326    0.000107  0.348252  0.291228  0.001056  \n",
       "33          382641    0.000015  0.047760  0.291228  0.001056  \n",
       "32          298326    0.000046  0.150724  0.291228  0.001056  \n",
       "31          160998    0.000046  0.148093  0.291228  0.001056  \n",
       "30          298326    0.000057  0.186241  0.291228  0.001056  \n",
       "29          278578    0.000098  0.335253  0.299242  0.000978  \n",
       "28          161033    0.000036  0.124243  0.299242  0.000978  \n",
       "27          160998    0.000043  0.148093  0.299242  0.000978  \n",
       "26          298326    0.000008  0.027253  0.299242  0.000978  \n",
       "25          266070    0.000020  0.067654  0.299242  0.000978  \n",
       "24          266070    0.000050  0.170698  0.299242  0.000978  \n",
       "23          278520    0.000066  0.223972  0.299242  0.000978  \n",
       "22          160998    0.000043  0.148093  0.299242  0.000978  \n",
       "21          266070    0.000020  0.068112  0.299242  0.000978  \n",
       "20          160998    0.000043  0.148093  0.299242  0.000978  \n",
       "19          298238    0.000044  0.151187  0.299242  0.000978  \n",
       "18          298313    0.000083  0.282331  0.299242  0.000978  \n",
       "17          298313    0.000125  0.426619  0.299242  0.000978  \n",
       "16          392289    0.000062  0.213249  0.299242  0.000978  \n",
       "15           53532    0.000125  0.425885  0.299242  0.000978  \n",
       "14          298326    0.000102  0.348252  0.299242  0.000978  \n",
       "13          298162    0.000003  0.010882  0.299242  0.000978  \n",
       "12          298326    0.000044  0.150724  0.299242  0.000978  \n",
       "11          160998    0.000043  0.148093  0.299242  0.000978  \n",
       "10          298326    0.000054  0.186241  0.299242  0.000978  \n",
       "9           278578    0.000097  0.335253  0.203655  0.001419  \n",
       "8           161033    0.000036  0.124243  0.203655  0.001419  \n",
       "7           160998    0.000043  0.148093  0.203655  0.001419  \n",
       "6            94855    0.000010  0.035051  0.203655  0.001419  \n",
       "5           266070    0.000020  0.067654  0.203655  0.001419  \n",
       "4           266070    0.000049  0.170698  0.203655  0.001419  \n",
       "3           278595    0.000064  0.222070  0.203655  0.001419  \n",
       "2           160998    0.000043  0.148093  0.203655  0.001419  \n",
       "1           266070    0.000020  0.068112  0.203655  0.001419  \n",
       "0           160998    0.000043  0.148093  0.203655  0.001419  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Audio\n",
    "# sound_file = 'reveil.mp3'\n",
    "# Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_proba[(df_proba['proba_id'] == 'p(R/S,E)') & (df_proba['sender'] =='ginger.dernehl@enron.com')].sort_values(by= 'likelihood' , ascending = False)\n",
    "df_proba = df_proba.drop(df_proba[(df_proba['receiver'] == df_proba['sender']) ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_proba[df_proba['mail_id'] == 298389.0].sort_values(['likelihood'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_proba[(df_proba['mail_id'] == 298389)  \\\n",
    "# #         & (df_proba['sender'] == 'karen.buckley@enron.com') \\\n",
    "# #         & (df_proba['receiver'] == 'c..aucoin@enron.com')  \\\n",
    "# #         & (df_proba['likelihood'] == 0) \n",
    "#         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path_to_data + 'predictions_random.txt')\n",
    "# df_proba[df_proba['mail_id'] == 298389.0].sort_values(['likelihood'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['richard.shapiro@enron.com', 'mark.whitt@enron.com',\n",
       "       'steven.j.kean@enron.com', 'shelley.corman@enron.com',\n",
       "       'rick.buy@enron.com', 'jarnold@enron.com',\n",
       "       'kimberly.watson@enron.com', 'e..haedicke@enron.com',\n",
       "       'jshankm@enron.com', 'jsteffe@enron.com'], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba[df_proba['mail_id'] == mail_id].sort_values(['likelihood'], ascending = False)[:10]['receiver'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chris.mahoney@enron.com anabel.soria@travelpark.com wk@transcarriers.com mpatterson@testmail.ercot.com expense.report@enron.com gateway1@pdq.net glwaas@calpx.com mitra.mujica@enron.com hjreed@powersrc.com brian.wesneske@enron.com'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.ix[0]['recipients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in submission.iterrows():\n",
    "    mail_id = row[0]\n",
    "    receivers_id = df_proba[df_proba['mail_id'] == mail_id].\\\n",
    "        sort_values(['likelihood'], ascending = False)[:10]['receiver'].values\n",
    "    receiver_list = \" \".join(receivers_id)\n",
    "    \n",
    "    submission.loc[index, 'recipients'] = receiver_list\n",
    "submission.to_csv('submission_test.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z3</td>\n",
       "      <td>0.433911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature     tfidf\n",
       "0      z3  0.433911"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_in_doc(X_mails_cv, vectorizer.get_feature_names(), 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
